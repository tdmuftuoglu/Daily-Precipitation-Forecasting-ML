{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# AUTHOR AND LICENSE INFORMATION\n",
        "# ==============================================================================\n",
        "# This code was developed by Dr. Tevfik Denizhan Müftüoğlu.\n",
        "# It can be used and/or modified with the condition of providing proper citation.\n",
        "#\n",
        "# Bu kod Dr. Tevfik Denizhan Müftüoğlu tarafından geliştirilmiştir.\n",
        "# Atıf verilmesi kaydıyla aynen ya da değiştirilerek kullanılabilir.\n",
        "# ==============================================================================\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# Adım 1: Kütüphaneleri Yükleme ve İçe Aktarma\n",
        "# ==============================================================================\n",
        "print(\"--- Installing required libraries... ---\")\n",
        "print(\"--- Gerekli kütüphaneler yükleniyor... ---\")\n",
        "!pip install pymannkendall -q\n",
        "!pip install prophet -q\n",
        "!pip install xgboost -q\n",
        "!pip install lightgbm -q\n",
        "!pip install graphviz -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pymannkendall as mk\n",
        "from scipy.stats import gumbel_r\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Models and Metrics\n",
        "from sklearn.ensemble import IsolationForest, RandomForestRegressor, StackingRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from prophet import Prophet\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, GRU\n",
        "from graphviz import Digraph\n",
        "\n",
        "# --- SET ALL RANDOM SEEDS FOR REPRODUCIBILITY ---\n",
        "# --- TEKRARLANABİLİRLİK İÇİN TÜM RASTGELELİK TOHUMLARINI AYARLAMA ---\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "print(\"\\n--- Random seeds set to 42 for reproducibility. ---\")\n",
        "print(\"--- Tekrarlanabilirlik için rastgelelik tohumları 42'ye ayarlandı. ---\")\n",
        "\n",
        "print(\"\\n--- Libraries installed and imported. ---\")\n",
        "print(\"--- Kütüphaneler yüklendi ve içe aktarıldı. ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: LOAD AND PREPARE THE DATA\n",
        "# Adım 2: Veriyi Yükleme ve Hazırlama\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Please select the NASAPOWERDATASET.csv file for upload: ---\")\n",
        "print(\"--- Lütfen yüklemek için NASAPOWERDATASET.csv dosyasını seçin: ---\")\n",
        "uploaded = files.upload()\n",
        "file_name = next(iter(uploaded))\n",
        "df = pd.read_csv(file_name)\n",
        "df['date'] = pd.to_datetime(df['YEAR'].astype(str) + '-' + df['DOY'].astype(str), format='%Y-%j')\n",
        "df.set_index('date', inplace=True)\n",
        "print(\"\\n--- Data successfully loaded and prepared. ---\")\n",
        "print(\"--- Veri başarıyla yüklendi ve hazırlandı. ---\")\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# ==============================================================================\n",
        "# ANALYSIS PART A: INDEPENDENT STATISTICAL ANALYSES\n",
        "# ANALİZ BÖLÜM A: BAĞIMSIZ İSTATİSTİKSEL ANALİZLER\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Starting Return Period Analysis (Gumbel)... ---\")\n",
        "print(\"--- Tekerrür Analizi (Gumbel) Başlatılıyor... ---\")\n",
        "annual_max_precip = df['PRECTOTCORR'].resample('Y').max()\n",
        "loc, scale = gumbel_r.fit(annual_max_precip)\n",
        "return_periods = np.array([2, 5, 10, 25, 50, 100])\n",
        "design_precip = gumbel_r.ppf(1 - 1 / return_periods, loc=loc, scale=scale)\n",
        "results_df_gumbel = pd.DataFrame({'Tekerrür Periyodu (Yıl)': return_periods, 'Tasarım Yağışı (mm/gün)': design_precip.round(2)})\n",
        "results_df_gumbel.to_csv('design_rainfall_table.csv', index=False)\n",
        "print(\"--- Return period analysis complete. Downloading 'design_rainfall_table.csv'... ---\")\n",
        "print(\"--- Tekerrür analizi tamamlandı. 'design_rainfall_table.csv' indiriliyor... ---\")\n",
        "files.download('design_rainfall_table.csv')\n",
        "\n",
        "# --- YENİ VE DOĞRU TREND ANALİZİ ---\n",
        "# --- NEW AND CORRECT TREND ANALYSIS ---\n",
        "print(\"\\n--- Starting Trend Analysis on Annual Maximum Precipitation... ---\")\n",
        "print(\"--- Yıllık Maksimum Yağış Üzerinde Trend Analizi Başlatılıyor... ---\")\n",
        "annual_max_precip_trend = df['PRECTOTCORR'].resample('Y').max()\n",
        "mk_result_annual_max = mk.original_test(annual_max_precip_trend)\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.plot(annual_max_precip_trend.index.year, annual_max_precip_trend, marker='o', linestyle='-', label='Yıllık Maksimum Günlük Yağış')\n",
        "trend_line = mk_result_annual_max.intercept + mk_result_annual_max.slope * annual_max_precip_trend.index.year\n",
        "plt.plot(annual_max_precip_trend.index.year, trend_line, 'r--', label=f'Theil-Sen Trend (p-değeri: {mk_result_annual_max.p:.3f})')\n",
        "plt.title('Yıllık Maksimum Günlük Yağış Miktarındaki Trend')\n",
        "plt.xlabel('Yıl')\n",
        "plt.ylabel('Maksimum Günlük Yağış (mm/gün)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('annual_max_precip_trend.png', dpi=300, bbox_inches='tight')\n",
        "print(\"--- Trend analysis complete. Downloading 'annual_max_precip_trend.png'... ---\")\n",
        "print(\"--- Trend analizi tamamlandı. 'annual_max_precip_trend.png' indiriliyor... ---\")\n",
        "files.download('annual_max_precip_trend.png')\n",
        "\n",
        "# ==============================================================================\n",
        "# ANALYSIS PART B: AUTOMATED FEATURE SELECTION & MODEL COMPETITION\n",
        "# ANALİZ BÖLÜM B: OTOMATİK ÖZELLİK SEÇİMİ VE MODEL YARIŞMASI\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Starting Automated Feature Selection... ---\")\n",
        "print(\"--- Otomatik Özellik Seçimi Başlatılıyor... ---\")\n",
        "POTENTIAL_FEATURES = ['T2M', 'RH2M', 'PS', 'WS10M', 'WD10M', 'ALLSKY_SFC_SW_DWN']\n",
        "TARGET_COL = 'PRECTOTCORR'\n",
        "df_fs = df[[TARGET_COL] + POTENTIAL_FEATURES].copy().dropna()\n",
        "for col in df_fs.columns: [df_fs.update({f'{col}_lag_{lag}': df_fs[col].shift(lag)}) for lag in range(1, 4)]\n",
        "df_fs = df_fs.dropna()\n",
        "X_fs = df_fs.drop(TARGET_COL, axis=1)\n",
        "y_fs = df_fs[TARGET_COL]\n",
        "explorer_model = xgb.XGBRegressor(n_estimators=100, n_jobs=-1, random_state=SEED).fit(X_fs, y_fs, verbose=False) # SEED added\n",
        "importances = pd.DataFrame({'feature': X_fs.columns, 'importance': explorer_model.feature_importances_}).sort_values('importance', ascending=False)\n",
        "TOP_FEATURES = importances['feature'].head(15).tolist()\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.barplot(x='importance', y='feature', data=importances.head(15)); plt.title('Feature Importance Ranking'); plt.xlabel('Importance'); plt.ylabel('Feature')\n",
        "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"--- Top {len(TOP_FEATURES)} features selected. Downloading 'feature_importance.png'... ---\")\n",
        "print(f\"--- En önemli {len(TOP_FEATURES)} özellik seçildi. 'feature_importance.png' indiriliyor... ---\")\n",
        "files.download('feature_importance.png')\n",
        "\n",
        "print(\"\\n--- Starting Final Model Competition (This may take a very long time)... ---\")\n",
        "print(\"--- Nihai Model Yarışması Başlatılıyor (Bu işlem ÇOK UZUN sürebilir)... ---\")\n",
        "# Data Prep\n",
        "df_final = df[[TARGET_COL] + POTENTIAL_FEATURES].copy()\n",
        "train_size = int(len(df_final) * 0.8)\n",
        "train_df, test_df = df_final.iloc[:train_size], df_final.iloc[train_size:]\n",
        "y_test_actual = test_df[TARGET_COL]\n",
        "performance_results = []\n",
        "X_train_tree, y_train_tree = X_fs.loc[train_df.index.min():train_df.index.max(), TOP_FEATURES], y_fs.loc[train_df.index.min():train_df.index.max()]\n",
        "X_test_tree, y_test_tree = X_fs.loc[test_df.index.min():test_df.index.max(), TOP_FEATURES], y_fs.loc[test_df.index.min():test_df.index.max()]\n",
        "\n",
        "# --- Model Training ---\n",
        "print(\"\\n1. Training All 11 Models...\")\n",
        "print(\"1. Tüm 11 Model Eğitiliyor...\")\n",
        "# Tree-based Models\n",
        "model_xgb = xgb.XGBRegressor(n_estimators=1000, early_stopping_rounds=50, eval_metric='rmse', random_state=SEED).fit(X_train_tree, y_train_tree, eval_set=[(X_test_tree, y_test_tree)], verbose=False) # SEED added\n",
        "predict_xgb = model_xgb.predict(X_test_tree)\n",
        "performance_results.append({'Model': 'XGBoost', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_tree, predict_xgb)), 'R-Kare (R²)': r2_score(y_test_tree, predict_xgb)})\n",
        "model_lgbm = lgb.LGBMRegressor(n_estimators=1000, random_state=SEED); model_lgbm.fit(X_train_tree, y_train_tree, eval_set=[(X_test_tree, y_test_tree)], callbacks=[lgb.early_stopping(50, verbose=False)]) # SEED added\n",
        "predict_lgbm = model_lgbm.predict(X_test_tree)\n",
        "performance_results.append({'Model': 'LightGBM', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_tree, predict_lgbm)), 'R-Kare (R²)': r2_score(y_test_tree, predict_lgbm)})\n",
        "model_rf = RandomForestRegressor(n_estimators=100, random_state=SEED, n_jobs=-1).fit(X_train_tree, y_train_tree) # SEED added\n",
        "predict_rf = model_rf.predict(X_test_tree)\n",
        "performance_results.append({'Model': 'Random Forest', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_tree, predict_rf)), 'R-Kare (R²)': r2_score(y_test_tree, predict_rf)})\n",
        "# Prophet\n",
        "FEATURES_FOR_PROPHET = [f for f in TOP_FEATURES if f in POTENTIAL_FEATURES and f in df_final.columns]\n",
        "prophet_df = df_final.reset_index().rename(columns={'date': 'ds', TARGET_COL: 'y'})\n",
        "train_prophet, test_prophet = prophet_df.iloc[:train_size], prophet_df.iloc[train_size:]\n",
        "model_prophet = Prophet(); [model_prophet.add_regressor(col) for col in FEATURES_FOR_PROPHET]\n",
        "model_prophet.fit(train_prophet)\n",
        "predict_prophet = model_prophet.predict(test_prophet.drop('y', axis=1))['yhat'].values\n",
        "performance_results.append({'Model': 'Prophet', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_actual, predict_prophet)), 'R-Kare (R²)': r2_score(y_test_actual, predict_prophet)})\n",
        "# SARIMAX\n",
        "X_sarimax_train = train_df[POTENTIAL_FEATURES]; X_sarimax_test = test_df[POTENTIAL_FEATURES]\n",
        "model_sarimax = SARIMAX(train_df[TARGET_COL], exog=X_sarimax_train, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0)).fit(disp=False)\n",
        "predict_sarimax = model_sarimax.get_forecast(steps=len(test_df), exog=X_sarimax_test).predicted_mean\n",
        "performance_results.append({'Model': 'SARIMAX', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_actual, predict_sarimax)), 'R-Kare (R²)': r2_score(y_test_actual, predict_sarimax)})\n",
        "# ANN\n",
        "scaler_ann = StandardScaler(); X_train_ann = scaler_ann.fit_transform(X_train_tree); X_test_ann = scaler_ann.transform(X_test_tree)\n",
        "model_ann = Sequential([Dense(64, activation='relu', input_shape=[X_train_ann.shape[1]]), Dense(32, activation='relu'), Dense(1)])\n",
        "model_ann.compile(optimizer='adam', loss='mean_squared_error'); model_ann.fit(X_train_ann, y_train_tree, epochs=50, batch_size=32, verbose=0)\n",
        "predict_ann = model_ann.predict(X_test_ann).flatten()\n",
        "performance_results.append({'Model': 'ANN', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_tree, predict_ann)), 'R-Kare (R²)': r2_score(y_test_tree, predict_ann)})\n",
        "# LSTM & GRU\n",
        "FEATURES_FOR_DL = [TARGET_COL] + [f for f in TOP_FEATURES if f in POTENTIAL_FEATURES and f in df_final.columns]\n",
        "scaler_dl = MinMaxScaler(); scaled_data = scaler_dl.fit_transform(df_final[FEATURES_FOR_DL])\n",
        "train_scaled, test_scaled = scaled_data[:train_size], scaled_data[train_size:]\n",
        "def create_multivariate_dataset(dataset, time_step=30):\n",
        "    dataX, dataY = [], []; [dataX.append(dataset[i:(i + time_step), :]) or dataY.append(dataset[i + time_step, 0]) for i in range(len(dataset) - time_step - 1)]; return np.array(dataX), np.array(dataY)\n",
        "time_step = 30\n",
        "X_train_dl, y_train_dl = create_multivariate_dataset(train_scaled, time_step); X_test_dl, _ = create_multivariate_dataset(test_scaled, time_step)\n",
        "model_lstm = Sequential([LSTM(50, input_shape=(X_train_dl.shape[1], X_train_dl.shape[2])), Dense(1)]); model_lstm.compile(optimizer='adam', loss='mean_squared_error'); model_lstm.fit(X_train_dl, y_train_dl, epochs=20, batch_size=64, verbose=0)\n",
        "predict_lstm_scaled = model_lstm.predict(X_test_dl)\n",
        "model_gru = Sequential([GRU(50, input_shape=(X_train_dl.shape[1], X_train_dl.shape[2])), Dense(1)]); model_gru.compile(optimizer='adam', loss='mean_squared_error'); model_gru.fit(X_train_dl, y_train_dl, epochs=20, batch_size=64, verbose=0)\n",
        "predict_gru_scaled = model_gru.predict(X_test_dl)\n",
        "dummy_lstm = np.zeros((len(predict_lstm_scaled), len(FEATURES_FOR_DL))); dummy_lstm[:,0] = predict_lstm_scaled.flatten(); predict_lstm = scaler_dl.inverse_transform(dummy_lstm)[:,0]\n",
        "dummy_gru = np.zeros((len(predict_gru_scaled), len(FEATURES_FOR_DL))); dummy_gru[:,0] = predict_gru_scaled.flatten(); predict_gru = scaler_dl.inverse_transform(dummy_gru)[:,0]\n",
        "y_test_dl_actual = y_test_actual.iloc[time_step+1:]\n",
        "performance_results.append({'Model': 'LSTM', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_dl_actual, predict_lstm)), 'R-Kare (R²)': r2_score(y_test_dl_actual, predict_lstm)})\n",
        "performance_results.append({'Model': 'GRU', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_dl_actual, predict_gru)), 'R-Kare (R²)': r2_score(y_test_dl_actual, predict_gru)})\n",
        "# Hybrid Models (Base and Optimized)\n",
        "df_hybrid = df_final.reset_index().rename(columns={'date':'ds', TARGET_COL:'y'})\n",
        "train_hybrid_prophet = df_hybrid.iloc[:train_size]\n",
        "model_prophet_base = Prophet().fit(train_hybrid_prophet[['ds', 'y']])\n",
        "full_forecast = model_prophet_base.predict(df_hybrid[['ds']])\n",
        "df_hybrid['prophet_forecast'] = full_forecast['yhat']\n",
        "df_hybrid['residuals'] = df_hybrid['y'] - df_hybrid['prophet_forecast']\n",
        "df_temp_for_lags = df_final.copy()\n",
        "for col in [TARGET_COL] + POTENTIAL_FEATURES: [df_temp_for_lags.update({f'{col}_lag_{lag}': df_temp_for_lags[col].shift(lag)}) for lag in range(1, 4)]\n",
        "df_temp_for_lags = df_temp_for_lags.dropna()\n",
        "df_hybrid_xgb = df_temp_for_lags.reset_index().rename(columns={'date':'ds'})\n",
        "df_hybrid_xgb = pd.merge(df_hybrid_xgb, df_hybrid[['ds', 'prophet_forecast', 'residuals']], on='ds', how='inner').set_index('ds')\n",
        "FEATURES_HYBRID = [f for f in df_hybrid_xgb.columns if f not in ['y', 'residuals', 'prophet_forecast', 'ds', TARGET_COL]]\n",
        "TARGET_HYBRID = 'residuals'\n",
        "train_size_hybrid = int(len(df_hybrid_xgb) * 0.8)\n",
        "X_train_h, X_test_h = df_hybrid_xgb.iloc[:train_size_hybrid][FEATURES_HYBRID], df_hybrid_xgb.iloc[train_size_hybrid:][FEATURES_HYBRID]\n",
        "y_train_h, y_test_h = df_hybrid_xgb.iloc[:train_size_hybrid][TARGET_HYBRID], df_hybrid_xgb.iloc[train_size_hybrid:][TARGET_HYBRID]\n",
        "prophet_test_forecast = df_hybrid_xgb['prophet_forecast'].iloc[train_size_hybrid:]\n",
        "y_test_hybrid_actual = y_test_h + prophet_test_forecast\n",
        "model_xgb_hybrid_base = xgb.XGBRegressor(n_estimators=1000, early_stopping_rounds=50, eval_metric='rmse', random_state=SEED).fit(X_train_h, y_train_h, eval_set=[(X_test_h, y_test_h)], verbose=False) # SEED added\n",
        "predict_residuals_base = model_xgb_hybrid_base.predict(X_test_h)\n",
        "predict_hybrid_base = prophet_test_forecast + predict_residuals_base\n",
        "performance_results.append({'Model': 'Hybrid (Base)', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_hybrid_actual, predict_hybrid_base)), 'R-Kare (R²)': r2_score(y_test_hybrid_actual, predict_hybrid_base)})\n",
        "param_grid = {'n_estimators': [100, 500, 1000], 'max_depth': [3, 5, 10], 'learning_rate': [0.01, 0.05, 0.1], 'subsample': [0.7, 0.9, 1.0]}\n",
        "random_search = RandomizedSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror', random_state=SEED), param_distributions=param_grid, n_iter=20, scoring='r2', cv=3, verbose=0, n_jobs=-1, random_state=SEED).fit(X_train_h, y_train_h) # SEED added\n",
        "best_hybrid_xgb = random_search.best_estimator_\n",
        "predict_residuals_optimized = best_hybrid_xgb.predict(X_test_h)\n",
        "predict_hybrid_optimized = prophet_test_forecast + predict_residuals_optimized\n",
        "performance_results.append({'Model': 'Hybrid (Optimized)', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_hybrid_actual, predict_hybrid_optimized)), 'R-Kare (R²)': r2_score(y_test_hybrid_actual, predict_hybrid_optimized)})\n",
        "# Stacking Model\n",
        "estimators = [('xgb', xgb.XGBRegressor(n_estimators=100, random_state=SEED)), ('lgbm', lgb.LGBMRegressor(n_estimators=100, random_state=SEED)), ('rf', RandomForestRegressor(n_estimators=50, random_state=SEED, n_jobs=-1))] # SEED added\n",
        "stacking_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
        "stacking_model.fit(X_train_tree, y_train_tree)\n",
        "predict_stacking = stacking_model.predict(X_test_tree)\n",
        "performance_results.append({'Model': 'Stacking Ensemble', 'RMSE (mm/gün)': np.sqrt(mean_squared_error(y_test_tree, predict_stacking)), 'R-Kare (R²)': r2_score(y_test_tree, predict_stacking)})\n",
        "\n",
        "# ==============================================================================\n",
        "# FINAL EVALUATION & VISUALIZATION\n",
        "# NİHAİ DEĞERLENDİRME VE GÖRSELLEŞTİRME\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Calculating Final Performances and Creating All Graphics... ---\")\n",
        "print(\"--- Nihai Performanslar Hesaplanıyor ve Tüm Grafikler Oluşturuluyor... ---\")\n",
        "performance_df = pd.DataFrame(performance_results).round(3).sort_values('R-Kare (R²)', ascending=False)\n",
        "print(\"\\n--- Final Model Comparison Results: ---\")\n",
        "print(\"--- Nihai Model Karşılaştırma Sonuçları: ---\")\n",
        "print(performance_df)\n",
        "performance_df.to_csv('ULTIMATE_FINAL_comparison.csv', index=False)\n",
        "print(\"\\n--- Downloading performance table 'ULTIMATE_FINAL_comparison.csv'... ---\")\n",
        "print(\"--- Performans tablosu 'ULTIMATE_FINAL_comparison.csv' indiriliyor... ---\")\n",
        "files.download('ULTIMATE_FINAL_comparison.csv')\n",
        "\n",
        "# --- Visualization 1: Performance Bar Plot ---\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='R-Kare (R²)', y='Model', data=performance_df, palette='viridis')\n",
        "plt.title('Final Model Performance Comparison (R-squared)', fontsize=16)\n",
        "plt.xlabel('R-squared (R²)', fontsize=12); plt.ylabel('Model', fontsize=12)\n",
        "plt.xlim(min(0, performance_df['R-Kare (R²)'].min()*1.1), max(performance_df['R-Kare (R²)']) * 1.1)\n",
        "plt.savefig('model_performance_barchart.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n--- Downloading performance bar chart 'model_performance_barchart.png'... ---\")\n",
        "print(\"--- Performans bar grafiği 'model_performance_barchart.png' indiriliyor... ---\")\n",
        "files.download('model_performance_barchart.png')\n",
        "\n",
        "# --- Visualization 2: Time Series Comparison Plot ---\n",
        "plt.figure(figsize=(18, 9))\n",
        "plt.plot(y_test_tree.index, y_test_tree.values, label='Actual Values', color='k', linewidth=2, alpha=0.6)\n",
        "plot_styles = {'XGBoost': {'color': 'purple', 'linestyle': '--'}, 'LightGBM': {'color': 'green', 'linestyle': ':'}, 'Random Forest': {'color': 'blue', 'linestyle': '-.'}, 'ANN': {'color': 'red', 'linestyle': '-'}, 'Stacking Ensemble': {'color': 'orange', 'linestyle': '--'}, 'Hybrid (Optimized)': {'color': 'cyan', 'linestyle': ':'}}\n",
        "top_models_df = performance_df.head(6)\n",
        "# Create a dictionary of predictions for easier lookup\n",
        "all_predictions = {\n",
        "    'XGBoost': pd.Series(predict_xgb, index=y_test_tree.index),\n",
        "    'LightGBM': pd.Series(predict_lgbm, index=y_test_tree.index),\n",
        "    'Random Forest': pd.Series(predict_rf, index=y_test_tree.index),\n",
        "    'ANN': pd.Series(predict_ann, index=y_test_tree.index),\n",
        "    'Stacking Ensemble': pd.Series(predict_stacking, index=y_test_tree.index),\n",
        "    'Hybrid (Optimized)': pd.Series(predict_hybrid_optimized, index=y_test_hybrid_actual.index),\n",
        "    'Hybrid (Base)': pd.Series(predict_hybrid_base, index=y_test_hybrid_actual.index),\n",
        "    'Prophet': pd.Series(predict_prophet, index=y_test_actual.index),\n",
        "    'SARIMAX': pd.Series(predict_sarimax, index=y_test_actual.index),\n",
        "    'LSTM': pd.Series(predict_lstm, index=y_test_dl_actual.index),\n",
        "    'GRU': pd.Series(predict_gru, index=y_test_dl_actual.index)\n",
        "}\n",
        "for index, row in top_models_df.iterrows():\n",
        "    model_name = row['Model']\n",
        "    if model_name in plot_styles:\n",
        "        r2_val = row['R-Kare (R²)']\n",
        "        prediction_series = all_predictions.get(model_name)\n",
        "        if prediction_series is not None:\n",
        "            plt.plot(prediction_series.index, prediction_series.values, label=f'{model_name} (R²={r2_val:.3f})', color=plot_styles[model_name]['color'], linestyle=plot_styles[model_name]['linestyle'])\n",
        "plt.title('Final Comparison of Top Performing Models'); plt.xlabel('Date'); plt.ylabel('Precipitation (mm/day)'); plt.legend()\n",
        "plt.savefig('ULTIMATE_FINAL_comparison.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n--- Downloading final comparison plot 'ULTIMATE_FINAL_comparison.png'... ---\")\n",
        "print(\"--- Nihai karşılaştırma grafiği 'ULTIMATE_FINAL_comparison.png' indiriliyor... ---\")\n",
        "files.download('ULTIMATE_FINAL_comparison.png')\n",
        "\n",
        "\n",
        "# --- Visualization 3: Actual vs. Predicted Scatter Plot for the Champion ---\n",
        "champion_model_name = performance_df.iloc[0]['Model']\n",
        "champion_predictions = all_predictions.get(champion_model_name)\n",
        "if champion_predictions is not None:\n",
        "    y_test_champion = y_test_hybrid_actual if 'Hybrid' in champion_model_name else (y_test_dl_actual if champion_model_name in ['LSTM', 'GRU'] else y_test_tree)\n",
        "    # Align indices for correct plotting\n",
        "    common_index = y_test_champion.index.intersection(champion_predictions.index)\n",
        "    y_test_champion = y_test_champion[common_index]\n",
        "    champion_predictions = champion_predictions[common_index]\n",
        "\n",
        "    champion_r2 = performance_df.iloc[0]['R-Kare (R²)']\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.scatter(y_test_champion, champion_predictions, alpha=0.5, label='Model Predictions')\n",
        "    min_val = 0; max_val = max(y_test_champion.max(), champion_predictions.max())\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction (R²=1)')\n",
        "    plt.title(f'Champion Model Performance: {champion_model_name} (R² = {champion_r2:.3f})', fontsize=16)\n",
        "    plt.xlabel('Actual Precipitation (mm/day)'); plt.ylabel('Predicted Precipitation (mm/day)'); plt.legend(); plt.grid(True); plt.axis('equal'); plt.xlim(left=min_val, right=max_val); plt.ylim(bottom=min_val, top=max_val)\n",
        "    plt.savefig('champion_model_scatter.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"\\n--- Downloading champion model scatter plot 'champion_model_scatter.png'... ---\")\n",
        "    print(\"--- Şampiyon modelin dağılım grafiği 'champion_model_scatter.png' indiriliyor... ---\")\n",
        "    files.download('champion_model_scatter.png')\n",
        "\n",
        "\n",
        "# --- Visualization 4: All Architectural Diagrams ---\n",
        "print(\"\\n--- Creating All Architectural Diagrams... ---\")\n",
        "print(\"--- Tüm Mimari Şemaları Oluşturuluyor... ---\")\n",
        "graph_attr = {'rankdir': 'TB', 'splines': 'ortho', 'nodesep': '0.8'}; node_attr = {'style': 'filled', 'shape': 'box', 'align': 'center', 'fontsize': '10', 'fontname': 'Helvetica'}; edge_attr = {'fontsize': '9', 'fontname': 'Helvetica'}\n",
        "# Decision Tree & RF\n",
        "rf_dot = Digraph('RandomForestConcept', graph_attr=graph_attr, node_attr=node_attr, edge_attr=edge_attr); rf_dot.attr(label='Random Forest Concept')\n",
        "with rf_dot.subgraph(name='cluster_0') as c: c.attr(color='white'); c.node('Input', 'Full Training Data', shape='parallelogram', fillcolor='lightgrey')\n",
        "with rf_dot.subgraph(name='cluster_1') as c: c.attr(label='Bootstrap Sampling & Feature Subspacing', style='dashed'); c.node('Data1', 'Data Subset 1\\n(Random Features)'); c.node('Data2', 'Data Subset 2\\n(Random Features)'); c.node('DataN', 'Data Subset N\\n(Random Features)')\n",
        "with rf_dot.subgraph(name='cluster_2') as c: c.attr(label='Independent Decision Trees', style='dashed'); c.node('Tree1', 'Decision Tree 1', fillcolor='lightblue'); c.node('Tree2', 'Decision Tree 2', fillcolor='lightblue'); c.node('TreeN', 'Decision Tree N', fillcolor='lightblue')\n",
        "rf_dot.node('Avg', 'Averaging\\nPredictions', shape='ellipse', fillcolor='orange'); rf_dot.node('Output', 'Final Prediction', shape='parallelogram', fillcolor='gold')\n",
        "rf_dot.edge('Input', 'Data1'); rf_dot.edge('Input', 'Data2'); rf_dot.edge('Input', 'DataN'); rf_dot.edge('Data1', 'Tree1'); rf_dot.edge('Data2', 'Tree2'); rf_dot.edge('DataN', 'TreeN'); rf_dot.edge('Tree1', 'Avg'); rf_dot.edge('Tree2', 'Avg'); rf_dot.edge('TreeN', 'Avg'); rf_dot.edge('Avg', 'Output')\n",
        "rf_dot.render('random_forest_concept', format='png', view=False); files.download('random_forest_concept.png')\n",
        "# ANN (MLP)\n",
        "ann_dot = Digraph('ANN_Architecture', graph_attr={'rankdir': 'LR', 'splines': 'line'}, node_attr=node_attr, edge_attr=edge_attr); ann_dot.attr(label='Artificial Neural Network (ANN) Architecture')\n",
        "with ann_dot.subgraph(name='cluster_0') as c: c.attr(label='Input Layer'); c.attr(color='white'); c.node_attr.update(shape='parallelogram', fillcolor='lightgrey'); c.node('xn', f'Input Features\\n({len(TOP_FEATURES)} Features)')\n",
        "with ann_dot.subgraph(name='cluster_1') as c: c.attr(label='Hidden Layer 1'); c.attr(color='white'); c.node_attr.update(shape='circle', fillcolor='lightblue'); c.node('h1_1', 'Neuron'); c.node('h1_n', '...')\n",
        "with ann_dot.subgraph(name='cluster_2') as c: c.attr(label='Hidden Layer 2'); c.attr(color='white'); c.node_attr.update(shape='circle', fillcolor='lightblue'); c.node('h2_1', 'Neuron'); c.node('h2_n', '...')\n",
        "with ann_dot.subgraph(name='cluster_3') as c: c.attr(label='Output Layer'); c.attr(color='white'); c.node_attr.update(shape='parallelogram', fillcolor='gold'); c.node('y', 'Precipitation\\nForecast')\n",
        "ann_dot.edge('xn', 'h1_1'); ann_dot.edge('xn', 'h1_n'); ann_dot.edge('h1_1', 'h2_1'); ann_dot.edge('h1_n', 'h2_n'); ann_dot.edge('h2_1', 'y'); ann_dot.edge('h2_n', 'y')\n",
        "ann_dot.render('ann_architecture', format='png', view=False); files.download('ann_architecture.png')\n",
        "# RNN Concept\n",
        "rnn_dot = Digraph('RNN_Concept', graph_attr=graph_attr, node_attr=node_attr, edge_attr=edge_attr); rnn_dot.attr(label='Recurrent Neural Network (RNN) Concept for LSTM/GRU')\n",
        "rnn_dot.node('xt', 'Input at time (t)\\n(Today\\'s Data)', shape='parallelogram', fillcolor='lightgrey'); rnn_dot.node('ht', 'Output at time (t)\\n(Today\\'s Prediction)', shape='parallelogram', fillcolor='gold')\n",
        "rnn_dot.node('A', 'Neural Network\\n(Hidden State)', fillcolor='lightblue'); rnn_dot.edge('xt', 'A'); rnn_dot.edge('A', 'ht'); rnn_dot.edge('A', 'A', label='Memory from (t-1)\\n(Yesterday\\'s Information)')\n",
        "rnn_dot.render('recurrent_neural_network_concept', format='png', view=False); files.download('recurrent_neural_network_concept.png')\n",
        "# Stacking Ensemble\n",
        "stack_dot = Digraph('Stacking_Architecture', graph_attr=graph_attr, node_attr=node_attr, edge_attr=edge_attr); stack_dot.attr(label='Stacking Ensemble Architecture')\n",
        "stack_dot.node('Input', f'Input Features\\n({len(TOP_FEATURES)} Features)', shape='parallelogram', fillcolor='lightgrey')\n",
        "with stack_dot.subgraph(name='cluster_base') as c: c.attr(label='Layer 0: Diverse Base Models', style='dashed'); c.node('XGB', 'XGBoost'); c.node('RF', 'Random Forest'); c.node('LGBM', 'LightGBM')\n",
        "stack_dot.node('Preds', 'Base Model Predictions\\n(New Features)', shape='parallelogram', fillcolor='orange')\n",
        "with stack_dot.subgraph(name='cluster_meta') as c: c.attr(label='Layer 1: Meta-Model', style='dashed'); c.node('Meta', 'Linear Regression')\n",
        "stack_dot.node('Output', 'Final Prediction', shape='parallelogram', fillcolor='gold')\n",
        "stack_dot.edge('Input', 'XGB'); stack_dot.edge('Input', 'RF'); stack_dot.edge('Input', 'LGBM'); stack_dot.edge('XGB', 'Preds'); stack_dot.edge('RF', 'Preds'); stack_dot.edge('LGBM', 'Preds'); stack_dot.edge('Preds', 'Meta'); stack_dot.edge('Meta', 'Output')\n",
        "stack_dot.render('stacking_architecture', format='png', view=False)\n",
        "print(\"--- Downloading all architectural diagrams... ---\")\n",
        "print(\"--- Tüm mimari şemaları indiriliyor... ---\")\n",
        "files.download('stacking_architecture.png')\n",
        "\n",
        "print(\"\\n\\n=== ALL ANALYSES AND VISUALIZATIONS COMPLETED ===\\n=== TÜM ANALİZLER VE GÖRSELLEŞTİRMELER TAMAMLANDI ===\")"
      ],
      "metadata": {
        "id": "Wwut3IUObBTw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}